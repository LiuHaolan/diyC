{
    "docs": [
        {
            "location": "/",
            "text": "Linux containers from scratch - diyC\n#\n\n\nLinux containers exist for a while and are now a mainstream\ntopic. This is an introduction on how they are created and what they\nactually are made of. If you want to see the code then head directly\nto \nthe GitHub repo\n otherwise read on\nthe topic you are interested in.\n\n\n\n\nNote\n\n\nAny suggestions or comments are welcome please don't hesitate\nand \nfile an issue on GitHub\n.\n\n\n\n\nWhat is a Linux container\n#\n\n\nContainers in some form exist for quite while even though \nwe don't\nalways think of them as containers\n. \n\n\n\n\nLinux container to put it simply it is a usual Linux process (or\ngroup of processes) with a limited (altered) view of the system.\n\n\n\n\nIt is achieved by utilizing\n\nOperating system level virtualization\n.\n\n\nBuilding containers from scratch\n#\n\n\nFollwing are the kernel features and other bits needed to build\ncontainers from scratch.\n\n\n\n\nLinux Namespaces\n\n\nImages and containers\n\n\n\n\nWhat is diyC\n#\n\n\nIt is a simple educational Linux container runtime. It is\nintentionally simple and leaves a lot of stuff out. It is\na \nsingle C file\n\nof roughly 500 lines including comments showing the core features of\nthe Linux used to build containers. It includes also the creation of a\ncontainer from an image to clarify how images and containers are\nrelated.\n\n\nnsexec\n#\n\n\nPart of the project is also\na \nnsexec\n binary\n \nwhich is is a very simple program that executes a local (host) command\nin Linux namespaces. See \nnsexec --help\n to see what namespaces are\navailable. Usage is very simple \nsudo ./nsexec -pnu myhost bash\n will\nstart a new bash in new pid, network and UTS namespace.",
            "title": "Home"
        },
        {
            "location": "/#linux-containers-from-scratch-diyc",
            "text": "Linux containers exist for a while and are now a mainstream\ntopic. This is an introduction on how they are created and what they\nactually are made of. If you want to see the code then head directly\nto  the GitHub repo  otherwise read on\nthe topic you are interested in.   Note  Any suggestions or comments are welcome please don't hesitate\nand  file an issue on GitHub .",
            "title": "Linux containers from scratch - diyC"
        },
        {
            "location": "/#what-is-a-linux-container",
            "text": "Containers in some form exist for quite while even though  we don't\nalways think of them as containers .    Linux container to put it simply it is a usual Linux process (or\ngroup of processes) with a limited (altered) view of the system.   It is achieved by utilizing Operating system level virtualization .",
            "title": "What is a Linux container"
        },
        {
            "location": "/#building-containers-from-scratch",
            "text": "Follwing are the kernel features and other bits needed to build\ncontainers from scratch.   Linux Namespaces  Images and containers",
            "title": "Building containers from scratch"
        },
        {
            "location": "/#what-is-diyc",
            "text": "It is a simple educational Linux container runtime. It is\nintentionally simple and leaves a lot of stuff out. It is\na  single C file \nof roughly 500 lines including comments showing the core features of\nthe Linux used to build containers. It includes also the creation of a\ncontainer from an image to clarify how images and containers are\nrelated.",
            "title": "What is diyC"
        },
        {
            "location": "/#nsexec",
            "text": "Part of the project is also\na  nsexec  binary  \nwhich is is a very simple program that executes a local (host) command\nin Linux namespaces. See  nsexec --help  to see what namespaces are\navailable. Usage is very simple  sudo ./nsexec -pnu myhost bash  will\nstart a new bash in new pid, network and UTS namespace.",
            "title": "nsexec"
        },
        {
            "location": "/namespaces/",
            "text": "Linux Namespaces\n#\n\n\nThis section covers how the containers are isolated from the host as\nwell as each other using the kernel namespaces. This is actually the\nmost significant kernel feature which virtualizes the resources and isolates\nthe processes from each other and using just namespaces creates a\ncontainers of sorts, see \nnsexec\n.\n\n\nNamespaces\n#\n\n\nPasting here the definition from the manual page\n\nnamespaces(7)\n \nas there probably isn't a better one.\n\n\n\n\nA namespace wraps a global system resource in an abstraction that\nmakes it appear to the processes within the namespace that they have\ntheir own isolated instance of the global resource.  Changes to the\nglobal resource are visible to other processes that are members of the\nnamespace, but are invisible to other processes.\n\n\n\n\nThere are 7 namespaces at the moment and a process can be in one or\nmore of them. There are always global namespaces for each of the types\nso that any process is always in some namespace of each type.\n\n\nLinux has so far following namespaces.\n\n\nNumber in the brackets is the kernel version when the namespace was\nintroduced\n\n\n\n\n\n\nMount (2.4.19)\n\n  Isolates the mount points. A process has it's own view of the mount\n  points and changes are not propagated to other namespaces.\n\n\nmount_namespaces(7)\n\n\n\n\n\n\nUTS (2.6.19)\n\n  Isolates the hostname and the  NIS domain name. Calling\n  \nsethostname(2)\n or\n  \nsetdomainname(2)\n is\n  affecting only the namespace.\n\n\n\n\n\n\nIPC (2.6.19)\n\n  Isolates IPC resources. System V IPC objects and POSIX message queues.\n\n\n\n\n\n\nPID (2.6.24)\n\n  Isolates the process ID number space. Processes in different PID\n  namespaces can have the same PID or can't see PIDs of different\n  namespace.\n\n\npid_namespaces(7)\n\n\n\n\n\n\nNetwork (2.6.29)\n\n  Isolates the network resources like network devices, IPv4 and IPv6\n  protocol stacks, IP routing tables, firewalls etc.\n\n\n\n\n\n\nUser (3.8)\n\n  Isolates the user and group resources, unprivileged user in the\n  \"root\" namespace can be a user ID 0 in the new namespace. When new\n  user namespace is created the user gets full\n  \ncapabilities(7)\n inside\n  the namespace.\n\n\nuser_namespaces(7)\n\n\n\n\n\n\nCgroups (4.6)\n\n  Isolates the view of the \n/proc/[pid]/cgroup\n and  \n/proc/[pid]/mountinfo\n.\n\n\ncgroup_namespaces(7)\n\n\n\n\n\n\nMount namespace\n#\n\n\nMount namespace isolates the mount points and effectively different\nnamespaces can have different filesystem trees as well as any changes\nin the mount points may or may not be propagated in the other\nnamespaces depending on the mount types (private, bind, slave etc),\nsee \nmount(8)\n. In\nthe container context it means that anything happening to mount points\ninside the container is not propagated elsewhere so they are\ncompletely isolated.\n\n\n\n\nImage courtesy of \nWonchang Song\n\n\nPID namespace\n#\n\n\nPID namespace isolated the PID numbers, they are a hierarchical\nstructure where the parent namespace can view all the PIDs in the\nchild namespaces. When a new namespace is created the first process\ngets the PID 1 and is a sort of init process of that namespace. It\nshould in the ideal world be able to reap any child processes as\notherwise it can actually exhaust the root PID space because of the\nhierarchical nature.\n\n\n\n\nNetwork namespace\n#\n\n\nNetwork namespace creates a completely new network stack including\nrouting tables, in a new network namespace you get just the loopback\ndevice \nlo\n and nothing else so you are actually unable to connect to\nthe network (see \nnsexec\n). Physical network interfaces can\nreside in only one namespace at a time so very often to connect the\nnamespace somewhere the virtual Ethernet device pair\n(\nveth pair\n)\nis used with together with\n\nLinux bridge\n.\nIn any case\nthe \nsetns(2)\n\ncomes handy for adding a device to the namespace.  \n\n\nCreating new namespaces\n#\n\n\nThere are two syscalls how to create a new namespace. \n\n\n\n\n\n\nclone(2)\n\n  is like \nfork(2)\n but\n  allows you to pick what context you share with the parent process.\n\n\n\n\n\n\nunshare(2)\n\n  is to disassociate from the parent process context and thus create a new\n  one.\n\n\n\n\n\n\nThere is also \nsetns(2)\n\nwhich allows you to enter an existing namespace.\n\n\nunshare and nsenter in the shell\n#\n\n\nYou can play with the namespaces in the shell too, \n\nnsenter(1)\n is\nthe command line equivalent\nof \nsetns(2)\n\nand \nunshare(1)\n\nis the equivalent\nof \nunshare(2)\n\nsyscall.\n\n\n$ unshare --fork --pid --mount-proc \n\n\n\n\nRuns a new shell in own PID namespace, it needs to remount the procfs\nas otherwise tools like \nps\n would still show the parent namespace.\n\n\nnsexec\n#\n\n\nnsexec\n is a minimal example on how to use namespaces to isolate\nprocesses and one could argue that it creates a container using the\nhost filesystem and programs.\n\n\n./nsexec --help\nCreate a child process that executes a shell command in new namespace(s),\nUsage: ./nsexec [OPTIONS] <CMD>\n\n    -h, --help           print this help\n    -n, --net            new network namespace\n    -p, --pid            new PID namespace\n    -u, --uts HOSTNAME   new UTS namespace\n    -v, --verbose        more verbose output\n\n    <CMD>                command to be executed\n\n\n\n\n\n\nSee the Code\n\n\nnsexec.c\n\n\n\n\nExample\n#\n\n\n$ sudo ./nsexec -npu myhost bash\nmyhost> ps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 10:45 pts/3    00:00:00 bash\nroot         6     1  0 10:45 pts/3    00:00:00 ps -ef\nmyhost> ip a\n1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\nmyhost> exit\nexit\n\n\n\n\nMore to read\n#\n\n\n\n\nNamespaces in operation, part 1: namespaces overview\n\n\nApplying mount namespaces\n\n\nIntroducing Linux Network Namespaces\n\n\nA Follow Up on Linux Network Namespaces",
            "title": "Linux Namespaces"
        },
        {
            "location": "/namespaces/#linux-namespaces",
            "text": "This section covers how the containers are isolated from the host as\nwell as each other using the kernel namespaces. This is actually the\nmost significant kernel feature which virtualizes the resources and isolates\nthe processes from each other and using just namespaces creates a\ncontainers of sorts, see  nsexec .",
            "title": "Linux Namespaces"
        },
        {
            "location": "/namespaces/#namespaces",
            "text": "Pasting here the definition from the manual page namespaces(7)  \nas there probably isn't a better one.   A namespace wraps a global system resource in an abstraction that\nmakes it appear to the processes within the namespace that they have\ntheir own isolated instance of the global resource.  Changes to the\nglobal resource are visible to other processes that are members of the\nnamespace, but are invisible to other processes.   There are 7 namespaces at the moment and a process can be in one or\nmore of them. There are always global namespaces for each of the types\nso that any process is always in some namespace of each type.  Linux has so far following namespaces.  Number in the brackets is the kernel version when the namespace was\nintroduced    Mount (2.4.19) \n  Isolates the mount points. A process has it's own view of the mount\n  points and changes are not propagated to other namespaces.  mount_namespaces(7)    UTS (2.6.19) \n  Isolates the hostname and the  NIS domain name. Calling\n   sethostname(2)  or\n   setdomainname(2)  is\n  affecting only the namespace.    IPC (2.6.19) \n  Isolates IPC resources. System V IPC objects and POSIX message queues.    PID (2.6.24) \n  Isolates the process ID number space. Processes in different PID\n  namespaces can have the same PID or can't see PIDs of different\n  namespace.  pid_namespaces(7)    Network (2.6.29) \n  Isolates the network resources like network devices, IPv4 and IPv6\n  protocol stacks, IP routing tables, firewalls etc.    User (3.8) \n  Isolates the user and group resources, unprivileged user in the\n  \"root\" namespace can be a user ID 0 in the new namespace. When new\n  user namespace is created the user gets full\n   capabilities(7)  inside\n  the namespace.  user_namespaces(7)    Cgroups (4.6) \n  Isolates the view of the  /proc/[pid]/cgroup  and   /proc/[pid]/mountinfo .  cgroup_namespaces(7)",
            "title": "Namespaces"
        },
        {
            "location": "/namespaces/#mount-namespace",
            "text": "Mount namespace isolates the mount points and effectively different\nnamespaces can have different filesystem trees as well as any changes\nin the mount points may or may not be propagated in the other\nnamespaces depending on the mount types (private, bind, slave etc),\nsee  mount(8) . In\nthe container context it means that anything happening to mount points\ninside the container is not propagated elsewhere so they are\ncompletely isolated.   Image courtesy of  Wonchang Song",
            "title": "Mount namespace"
        },
        {
            "location": "/namespaces/#pid-namespace",
            "text": "PID namespace isolated the PID numbers, they are a hierarchical\nstructure where the parent namespace can view all the PIDs in the\nchild namespaces. When a new namespace is created the first process\ngets the PID 1 and is a sort of init process of that namespace. It\nshould in the ideal world be able to reap any child processes as\notherwise it can actually exhaust the root PID space because of the\nhierarchical nature.",
            "title": "PID namespace"
        },
        {
            "location": "/namespaces/#network-namespace",
            "text": "Network namespace creates a completely new network stack including\nrouting tables, in a new network namespace you get just the loopback\ndevice  lo  and nothing else so you are actually unable to connect to\nthe network (see  nsexec ). Physical network interfaces can\nreside in only one namespace at a time so very often to connect the\nnamespace somewhere the virtual Ethernet device pair\n( veth pair )\nis used with together with Linux bridge .\nIn any case\nthe  setns(2) \ncomes handy for adding a device to the namespace.",
            "title": "Network namespace"
        },
        {
            "location": "/namespaces/#creating-new-namespaces",
            "text": "There are two syscalls how to create a new namespace.     clone(2) \n  is like  fork(2)  but\n  allows you to pick what context you share with the parent process.    unshare(2) \n  is to disassociate from the parent process context and thus create a new\n  one.    There is also  setns(2) \nwhich allows you to enter an existing namespace.",
            "title": "Creating new namespaces"
        },
        {
            "location": "/namespaces/#unshare-and-nsenter-in-the-shell",
            "text": "You can play with the namespaces in the shell too,  nsenter(1)  is\nthe command line equivalent\nof  setns(2) \nand  unshare(1) \nis the equivalent\nof  unshare(2) \nsyscall.  $ unshare --fork --pid --mount-proc   Runs a new shell in own PID namespace, it needs to remount the procfs\nas otherwise tools like  ps  would still show the parent namespace.",
            "title": "unshare and nsenter in the shell"
        },
        {
            "location": "/namespaces/#nsexec",
            "text": "nsexec  is a minimal example on how to use namespaces to isolate\nprocesses and one could argue that it creates a container using the\nhost filesystem and programs.  ./nsexec --help\nCreate a child process that executes a shell command in new namespace(s),\nUsage: ./nsexec [OPTIONS] <CMD>\n\n    -h, --help           print this help\n    -n, --net            new network namespace\n    -p, --pid            new PID namespace\n    -u, --uts HOSTNAME   new UTS namespace\n    -v, --verbose        more verbose output\n\n    <CMD>                command to be executed   See the Code  nsexec.c",
            "title": "nsexec"
        },
        {
            "location": "/namespaces/#example",
            "text": "$ sudo ./nsexec -npu myhost bash\nmyhost> ps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 10:45 pts/3    00:00:00 bash\nroot         6     1  0 10:45 pts/3    00:00:00 ps -ef\nmyhost> ip a\n1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\nmyhost> exit\nexit",
            "title": "Example"
        },
        {
            "location": "/namespaces/#more-to-read",
            "text": "Namespaces in operation, part 1: namespaces overview  Applying mount namespaces  Introducing Linux Network Namespaces  A Follow Up on Linux Network Namespaces",
            "title": "More to read"
        },
        {
            "location": "/cgroups/",
            "text": "Linux cgroups a.k.a. Control Groups\n#\n\n\nWithout setting limits on resources the isolation of containers\ndoesn't work well because a rogue container can eat up all the memory\nor file descriptors of the host system and thus bring everything\ndown.\n\n\nWe can use usual limits \n\ngetrlimit(2)\n\nto achieve something but it is far from enough and brings issues\nbecause of UIDs mappings, capabilities and so on.\n\n\nCgroups\n#\n\n\nCgroups is a Linux kernel feature to limit, police and account the\nresource usage for a set of processes and containers are just\nthat.\n\n\nCgroups are hierarchical and child cgroups inherit certain attributes\nfrom their parent cgroup and cannot override those set by\nparent. Every process or thread belongs to one cgroup in given\nsubsystem.\n\n\nThere are actually two versions of the implementation\n\nv1\n\nand \nv2\n where\nthe main difference is that v1 operates on thread level but v2 is\nsimpler and considers only processes.\n\n\nCgroup subsystems\n#\n\n\nSome of the subsystems are listed here see\n\nFedora Resource Management Guide\n for\nall the details.\n\n\n\n\nblkio\n - limits on IO\n\n\ncpu\n - cpu scheduling\n\n\ncpuset\n - assigns CPU(s)n on multicore systems\n\n\ndevices\n - controls access to devices\n\n\nmemory\n - memory limits like rss, swap etc.\n\n\n\n\nManaging cgroups\n#\n\n\nCgroups have no syscalls but are managed through a filesystem under\n\n/sys/fs/cgroup\n where each of the subsystem is directory.\n\n\nIt is very easy to create a new group in any of the subsystems just\ncreate subdirectory and kernel will populate it with the files.\n\n\n\n$ mkdir /sys/fs/cgroup/memory/mygroup\n$ ls -la /sys/fs/cgroup/memory/mygroup\n\ntotal 0\ndrwxr-xr-x 2 root root 0 28.04.2017 13:05 ./\ndr-xr-xr-x 6 root root 0 28.04.2017 13:03 ../\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 cgroup.clone_children\n--w--w--w- 1 root root 0 28.04.2017 13:05 cgroup.event_control\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 cgroup.procs\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.failcnt\n--w------- 1 root root 0 28.04.2017 13:05 memory.force_empty\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.failcnt\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.limit_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.max_usage_in_bytes\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.slabinfo\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.failcnt\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.limit_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.max_usage_in_bytes\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.usage_in_bytes\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.usage_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.limit_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.max_usage_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.failcnt\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.limit_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.max_usage_in_bytes\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.usage_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.move_charge_at_immigrate\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.numa_stat\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.oom_control\n---------- 1 root root 0 28.04.2017 13:05 memory.pressure_level\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.soft_limit_in_bytes\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.stat\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.swappiness\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.usage_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.use_hierarchy\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 notify_on_release\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 tasks\n\n\n\n\n\nNow we can set a memory limit to 10 MB for this group.\n\n\n$ echo 1000000 > /sys/fs/cgroup/memory/mygroup/memory.limit_in_bytes\n\n\n\n\nTo add a process to our group we need to just append the pid to\n\ncgroup.procs\n file.\n\n\n echo $$ > /sys/fs/cgroup/memory/groupname/cgroup.procs\n\n\n\n\nThe shell and it's children are now limited to 10MB which you can\neasily check by allocation enough memory.\n\n\nUse \nrmdir\n to remove the group. The group cannot be removed untill\nthere are no processes running in that group.\n\n\n\n\nCode\n\n\nThe cgroup and limits are set up after the \nclone\n when the pid of\nthe container is known.\n\ndiyc.c:198-232\n\n\nExample using diyc\n\n\n\n\nMore to read\n#\n\n\n\n\nLinux kernel cgroups v1\n\n\nLinux kernel cgroups v2\n\n\nControl groups on Ubuntu Server Guide\n\n\nRHEL Resource Management Guide",
            "title": "Linux Cgroups"
        },
        {
            "location": "/cgroups/#linux-cgroups-aka-control-groups",
            "text": "Without setting limits on resources the isolation of containers\ndoesn't work well because a rogue container can eat up all the memory\nor file descriptors of the host system and thus bring everything\ndown.  We can use usual limits  getrlimit(2) \nto achieve something but it is far from enough and brings issues\nbecause of UIDs mappings, capabilities and so on.",
            "title": "Linux cgroups a.k.a. Control Groups"
        },
        {
            "location": "/cgroups/#cgroups",
            "text": "Cgroups is a Linux kernel feature to limit, police and account the\nresource usage for a set of processes and containers are just\nthat.  Cgroups are hierarchical and child cgroups inherit certain attributes\nfrom their parent cgroup and cannot override those set by\nparent. Every process or thread belongs to one cgroup in given\nsubsystem.  There are actually two versions of the implementation v1 \nand  v2  where\nthe main difference is that v1 operates on thread level but v2 is\nsimpler and considers only processes.",
            "title": "Cgroups"
        },
        {
            "location": "/cgroups/#cgroup-subsystems",
            "text": "Some of the subsystems are listed here see Fedora Resource Management Guide  for\nall the details.   blkio  - limits on IO  cpu  - cpu scheduling  cpuset  - assigns CPU(s)n on multicore systems  devices  - controls access to devices  memory  - memory limits like rss, swap etc.",
            "title": "Cgroup subsystems"
        },
        {
            "location": "/cgroups/#managing-cgroups",
            "text": "Cgroups have no syscalls but are managed through a filesystem under /sys/fs/cgroup  where each of the subsystem is directory.  It is very easy to create a new group in any of the subsystems just\ncreate subdirectory and kernel will populate it with the files.  \n$ mkdir /sys/fs/cgroup/memory/mygroup\n$ ls -la /sys/fs/cgroup/memory/mygroup\n\ntotal 0\ndrwxr-xr-x 2 root root 0 28.04.2017 13:05 ./\ndr-xr-xr-x 6 root root 0 28.04.2017 13:03 ../\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 cgroup.clone_children\n--w--w--w- 1 root root 0 28.04.2017 13:05 cgroup.event_control\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 cgroup.procs\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.failcnt\n--w------- 1 root root 0 28.04.2017 13:05 memory.force_empty\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.failcnt\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.limit_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.max_usage_in_bytes\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.slabinfo\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.failcnt\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.limit_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.max_usage_in_bytes\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.usage_in_bytes\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.usage_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.limit_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.max_usage_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.failcnt\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.limit_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.max_usage_in_bytes\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.usage_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.move_charge_at_immigrate\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.numa_stat\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.oom_control\n---------- 1 root root 0 28.04.2017 13:05 memory.pressure_level\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.soft_limit_in_bytes\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.stat\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.swappiness\n-r--r--r-- 1 root root 0 28.04.2017 13:05 memory.usage_in_bytes\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.use_hierarchy\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 notify_on_release\n-rw-r--r-- 1 root root 0 28.04.2017 13:05 tasks  Now we can set a memory limit to 10 MB for this group.  $ echo 1000000 > /sys/fs/cgroup/memory/mygroup/memory.limit_in_bytes  To add a process to our group we need to just append the pid to cgroup.procs  file.   echo $$ > /sys/fs/cgroup/memory/groupname/cgroup.procs  The shell and it's children are now limited to 10MB which you can\neasily check by allocation enough memory.  Use  rmdir  to remove the group. The group cannot be removed untill\nthere are no processes running in that group.   Code  The cgroup and limits are set up after the  clone  when the pid of\nthe container is known. diyc.c:198-232  Example using diyc",
            "title": "Managing cgroups"
        },
        {
            "location": "/cgroups/#more-to-read",
            "text": "Linux kernel cgroups v1  Linux kernel cgroups v2  Control groups on Ubuntu Server Guide  RHEL Resource Management Guide",
            "title": "More to read"
        },
        {
            "location": "/images-containers/",
            "text": "Images and Containers\n#\n\n\nThis section covers how the container is created from an image.\n\n\nWhat is an image?\n#\n\n\nContainer images are basically \njust tarballs\n or tarballs of\ntarballs. The tarball contains files and directories needed by the\nprogram running in the container. A very simple way\nhow to inspect an image is to export it using docker.\n\n\n\n\n\n\nSpin the desired container up, in this case a base debian image.\n\n\n$ docker run -ti debian bash\n\n\n\n\n\n\n\nIn other terminal, find the container and export it.\n\n\n$ docker ps\nCONTAINER ID        IMAGE               COMMAND\nf222a193be90        debian              \"bash\"\n\n$ docker export f222a193be90 > deian.tar\n\n\n\n\n\n\n\nStop the container\n\n\nroot@f222a193be90:/> exit\n\n\n\n\n\n\n\nUntar the image into directory.\n\n\n$ mkdir debain-image\n$ tar -xf debian.tar -C debian-image\n\n\n\n\n\n\n\nInspect what's inside. It looks like a usual GNU/Linux filesystem layout.\n\n\n$ ls -la debian-image\ntotal 92\ndrwxr-xr-x  21 wvi wvi  4096 23.04.2017 11:07 ./\ndrwxrwxrwx 113 wvi wvi 12288 23.04.2017 11:07 ../\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:29 bin/\ndrwxr-xr-x   2 wvi wvi  4096 28.12.2016 18:42 boot/\ndrwxr-xr-x   4 wvi wvi  4096 23.04.2017 11:00 dev/\ndrwxr-xr-x  41 wvi wvi  4096 23.04.2017 11:00 etc/\ndrwxr-xr-x   2 wvi wvi  4096 28.12.2016 18:42 home/\ndrwxr-xr-x   9 wvi wvi  4096 27.11.2014 20:59 lib/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:27 lib64/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:26 media/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:26 mnt/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:26 opt/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:29 proc/\ndrwx------   2 wvi wvi  4096 21.03.2017 00:26 root/\ndrwxr-xr-x   3 wvi wvi  4096 21.03.2017 00:26 run/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:29 sbin/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:26 srv/\ndrwxr-xr-x   2 wvi wvi  4096 06.04.2015 20:44 sys/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:29 tmp/\ndrwxr-xr-x  10 wvi wvi  4096 21.03.2017 00:26 usr/\ndrwxr-xr-x  11 wvi wvi  4096 21.03.2017 00:26 var/\n-rwxr-xr-x   1 wvi wvi     0 23.04.2017 11:00 .dockerenv*\n\n\n\n\n\n\n\nCreating the image\n#\n\n\nTo create an image for the diyC the easiest is to \nexport the docker\nimage\n.\n\n\nGenerally for containers there are many other ways how to create an\nimage but it is out of scope of this project so here is just a few\npointers.\n\n\n\n\n\n\nStatically linked programs where you need just that one binary\n  nothing else so something along those lines should suffice. That's\n  for example what you can do with \nGo programs\n.\n\n\n$ mkdir image\n$ cp <my-statically-linked-binary> image\n$ tar -cf image.tar image\n\n\n\n\n\n\n\nhttps://buildroot.org/\n is a toolbox for\n  creating embedded Linux systems but you can very easily create a\n  custom installation which will be very small. See a\n  \ngreat talk on this topic from Brian \"Redbeard\" Harrington\n from\n  \ncoreOS\n.\n\n\n\n\n\n\nGet your filesystem layout and copy files needed. you can use\n  package managers like \ndnf\n, \nyum\n, \ndebootsrap\n etc. and tar the\n  structure up.\n\n\n\n\n\n\nEasy way to verify that the tarball makes sense is to import it to docker\nusing \ndocker import tarball.tar\n.\n\n\nHow a container is created from an image?\n#\n\n\nThe main magic is layers because containers are\nlike \nOgres\n. The\ncontainer's filesystem is usually made of at least two layers many\ntimes there are more layers involved but that doesn't change the core\nconcept where one layer is the image and the other is a writable\ntemporary directory for the container to write files so that the image\nremains immutable. To achieve such behavior you need a so\ncalled \nunion mount\n which\nbasically mounts a new filesystem combining two or more\ndirectories/filesystems together into one.\n\n\n\n\nAbove: Simplified unioning filesystem scheme\n\n\nSuch a unified filesystem is then mounted under some temp working directory\nand in the container it is changed to be the root\nfilesystem using the\n\npivot_root syscall\n.\n\npivot_root\n\nis almost like\na \nchroot\n but you\nget to keep access to the original old root so you can for example\ncopy some configuration files to the new root.\n\n\n\n\nCode\n\n\nSee the implementation in \ndiy.c:304-330\n\n\n\n\nVery similar behavior is also possible using completely different\napproaches, i.e utilizing subvolumes and snapshots\nof \nbtrfs\n or\nusing \ndevicemapper\n. Docker\nuses devicemapper approach on many systems by default and has a very\ngood description of the \n\ndevicemapper approach\n.\n\n\nUnioning filesystems in Linux\n#\n\n\nHistorically there were couple of options on Linux but only one of\nthem ended up in the mainline kernel. Describing the history and\ndetails is out of the scope but the main ones are :\n\n\n\n\nUnionFS\n\n\naufs\n\n\noverlayFS\n\n\n\n\nToday the easiest option is to use overlayfs filesystem because it\nwas merged to mainline kernel in version 3.18. It is actually called\noverlay since the merge. To check if you are able to use it see\n\n/proc/filesystems\n file (\nman 5 filesystems\n).\n\n\n\n\noverlay kernel module\n\n\nVery often it does not show up in the \n/proc/filesystems\n because\nit is loaded only if it is used so try \nmodprobe overlay\n to load the kernel module.\n\n\n\n\nUsing overlay filesystem\n#\n\n\nIn the overlayfs there are two layers, \nlowerdir\n which is\nalways read only and \nupperdir\n which is writable. You can actually have\nmore \nlowerdir\n directories which are all read only as any changes are\nalways stored in the \nupperdir\n. It can be used in many ways\n(i.e. Live CDs) and is not specific to containers.\n\n\nYou can give it a try yourself easily from a command line.\n\n\nOverlay \nmount(8)\n options.\n\n\n# mount -t overlay overlay -o lowerdir=/lower1:/lower2,upperdir=/upper,workdir=/work /merged\n\n\n\n\n\n\nworkdir\n\n\nThe \nworkdir\n parameter must be on the same filesystem as the\n\nupperdir\n directory and it is used for certain atomic\noperations. \nlowerdir\n can be on a different filesystem though.\n\n\n\n\n# In tmp create the needed directory structure\n$ mkdir /tmp/lower /tmp/upper /tmp/workdir /tmp/merged\n# and mount an overlay fs\n$ sudo mount -t overlay -o \\\n  lowerdir=/tmp/lower,\\\n  upperdir=/tmp/upper,\\\n  workdir=/tmp/workdir \\\n  none /tmp/merged\n\n\n\n\nIf you play around creating/writing/deleting files and directories in\nthe \nlower\n, \nupper\n and  \nmerged\n you can observe the following.\n\n\nObservations\n#\n\n\n\n\n\n\nIf there are directories in both \nlower\n and \nupper\n their content\n  is merged.\n\n\n\n\n\n\nFiles created in the \nlower\n or \nupper\n directory are visible in the\n  \nmerged\n.\n\n\n\n\n\n\nAny files created in the merged are actually created in the \nupper\n.\n\n\n\n\n\n\nWriting to existing files appears again only in \nupper\n even if the\n  file was originally in \nlower\n, the file is \ncopied up\n.\n\n\n\n\n\n\nDeleting a file or directory in \nmerged\n that was in the \nlower\n,\n  removes it from merged but not \nlower\n. It creates a so called\n  \"whiteout\" file/directory in the \nupper\n.\n\n\n\n\n\n\nContainer filesystem is created in the same fashion, image is the\n\nlowerdir\n and container specific files are in the \nupperdir\n. Inside the\ncontainer you see the \nmerged\n.\n\n\nMore to read\n#\n\n\n\n\nOverlay documentation in kernel\n\n\nDocker and OverlayFS in practice\n\n\nDocker and the Device Mapper storage driver\n\n\nUnioning file systems: Architecture, features, and design choices\n\n\nUnion file systems: Implementations, part I\n\n\nUnioning file systems: Implementations, part 2\n\n\nAnother union filesystem approach",
            "title": "Images and containers"
        },
        {
            "location": "/images-containers/#images-and-containers",
            "text": "This section covers how the container is created from an image.",
            "title": "Images and Containers"
        },
        {
            "location": "/images-containers/#what-is-an-image",
            "text": "Container images are basically  just tarballs  or tarballs of\ntarballs. The tarball contains files and directories needed by the\nprogram running in the container. A very simple way\nhow to inspect an image is to export it using docker.    Spin the desired container up, in this case a base debian image.  $ docker run -ti debian bash    In other terminal, find the container and export it.  $ docker ps\nCONTAINER ID        IMAGE               COMMAND\nf222a193be90        debian              \"bash\"\n\n$ docker export f222a193be90 > deian.tar    Stop the container  root@f222a193be90:/> exit    Untar the image into directory.  $ mkdir debain-image\n$ tar -xf debian.tar -C debian-image    Inspect what's inside. It looks like a usual GNU/Linux filesystem layout.  $ ls -la debian-image\ntotal 92\ndrwxr-xr-x  21 wvi wvi  4096 23.04.2017 11:07 ./\ndrwxrwxrwx 113 wvi wvi 12288 23.04.2017 11:07 ../\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:29 bin/\ndrwxr-xr-x   2 wvi wvi  4096 28.12.2016 18:42 boot/\ndrwxr-xr-x   4 wvi wvi  4096 23.04.2017 11:00 dev/\ndrwxr-xr-x  41 wvi wvi  4096 23.04.2017 11:00 etc/\ndrwxr-xr-x   2 wvi wvi  4096 28.12.2016 18:42 home/\ndrwxr-xr-x   9 wvi wvi  4096 27.11.2014 20:59 lib/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:27 lib64/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:26 media/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:26 mnt/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:26 opt/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:29 proc/\ndrwx------   2 wvi wvi  4096 21.03.2017 00:26 root/\ndrwxr-xr-x   3 wvi wvi  4096 21.03.2017 00:26 run/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:29 sbin/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:26 srv/\ndrwxr-xr-x   2 wvi wvi  4096 06.04.2015 20:44 sys/\ndrwxr-xr-x   2 wvi wvi  4096 21.03.2017 00:29 tmp/\ndrwxr-xr-x  10 wvi wvi  4096 21.03.2017 00:26 usr/\ndrwxr-xr-x  11 wvi wvi  4096 21.03.2017 00:26 var/\n-rwxr-xr-x   1 wvi wvi     0 23.04.2017 11:00 .dockerenv*",
            "title": "What is an image?"
        },
        {
            "location": "/images-containers/#creating-the-image",
            "text": "To create an image for the diyC the easiest is to  export the docker\nimage .  Generally for containers there are many other ways how to create an\nimage but it is out of scope of this project so here is just a few\npointers.    Statically linked programs where you need just that one binary\n  nothing else so something along those lines should suffice. That's\n  for example what you can do with  Go programs .  $ mkdir image\n$ cp <my-statically-linked-binary> image\n$ tar -cf image.tar image    https://buildroot.org/  is a toolbox for\n  creating embedded Linux systems but you can very easily create a\n  custom installation which will be very small. See a\n   great talk on this topic from Brian \"Redbeard\" Harrington  from\n   coreOS .    Get your filesystem layout and copy files needed. you can use\n  package managers like  dnf ,  yum ,  debootsrap  etc. and tar the\n  structure up.    Easy way to verify that the tarball makes sense is to import it to docker\nusing  docker import tarball.tar .",
            "title": "Creating the image"
        },
        {
            "location": "/images-containers/#how-a-container-is-created-from-an-image",
            "text": "The main magic is layers because containers are\nlike  Ogres . The\ncontainer's filesystem is usually made of at least two layers many\ntimes there are more layers involved but that doesn't change the core\nconcept where one layer is the image and the other is a writable\ntemporary directory for the container to write files so that the image\nremains immutable. To achieve such behavior you need a so\ncalled  union mount  which\nbasically mounts a new filesystem combining two or more\ndirectories/filesystems together into one.   Above: Simplified unioning filesystem scheme  Such a unified filesystem is then mounted under some temp working directory\nand in the container it is changed to be the root\nfilesystem using the pivot_root syscall . pivot_root \nis almost like\na  chroot  but you\nget to keep access to the original old root so you can for example\ncopy some configuration files to the new root.   Code  See the implementation in  diy.c:304-330   Very similar behavior is also possible using completely different\napproaches, i.e utilizing subvolumes and snapshots\nof  btrfs  or\nusing  devicemapper . Docker\nuses devicemapper approach on many systems by default and has a very\ngood description of the  devicemapper approach .",
            "title": "How a container is created from an image?"
        },
        {
            "location": "/images-containers/#unioning-filesystems-in-linux",
            "text": "Historically there were couple of options on Linux but only one of\nthem ended up in the mainline kernel. Describing the history and\ndetails is out of the scope but the main ones are :   UnionFS  aufs  overlayFS   Today the easiest option is to use overlayfs filesystem because it\nwas merged to mainline kernel in version 3.18. It is actually called\noverlay since the merge. To check if you are able to use it see /proc/filesystems  file ( man 5 filesystems ).   overlay kernel module  Very often it does not show up in the  /proc/filesystems  because\nit is loaded only if it is used so try  modprobe overlay  to load the kernel module.",
            "title": "Unioning filesystems in Linux"
        },
        {
            "location": "/images-containers/#using-overlay-filesystem",
            "text": "In the overlayfs there are two layers,  lowerdir  which is\nalways read only and  upperdir  which is writable. You can actually have\nmore  lowerdir  directories which are all read only as any changes are\nalways stored in the  upperdir . It can be used in many ways\n(i.e. Live CDs) and is not specific to containers.  You can give it a try yourself easily from a command line.  Overlay  mount(8)  options.  # mount -t overlay overlay -o lowerdir=/lower1:/lower2,upperdir=/upper,workdir=/work /merged   workdir  The  workdir  parameter must be on the same filesystem as the upperdir  directory and it is used for certain atomic\noperations.  lowerdir  can be on a different filesystem though.   # In tmp create the needed directory structure\n$ mkdir /tmp/lower /tmp/upper /tmp/workdir /tmp/merged\n# and mount an overlay fs\n$ sudo mount -t overlay -o \\\n  lowerdir=/tmp/lower,\\\n  upperdir=/tmp/upper,\\\n  workdir=/tmp/workdir \\\n  none /tmp/merged  If you play around creating/writing/deleting files and directories in\nthe  lower ,  upper  and   merged  you can observe the following.",
            "title": "Using overlay filesystem"
        },
        {
            "location": "/images-containers/#observations",
            "text": "If there are directories in both  lower  and  upper  their content\n  is merged.    Files created in the  lower  or  upper  directory are visible in the\n   merged .    Any files created in the merged are actually created in the  upper .    Writing to existing files appears again only in  upper  even if the\n  file was originally in  lower , the file is  copied up .    Deleting a file or directory in  merged  that was in the  lower ,\n  removes it from merged but not  lower . It creates a so called\n  \"whiteout\" file/directory in the  upper .    Container filesystem is created in the same fashion, image is the lowerdir  and container specific files are in the  upperdir . Inside the\ncontainer you see the  merged .",
            "title": "Observations"
        },
        {
            "location": "/images-containers/#more-to-read",
            "text": "Overlay documentation in kernel  Docker and OverlayFS in practice  Docker and the Device Mapper storage driver  Unioning file systems: Architecture, features, and design choices  Union file systems: Implementations, part I  Unioning file systems: Implementations, part 2  Another union filesystem approach",
            "title": "More to read"
        },
        {
            "location": "/diyc/install/",
            "text": "Getting started\n#\n\n\n\n\niptables\n\n\ndiyC plays with iptables to get the routing and isolation running so if\nyou have your own iptables rules make sure to save them before doing\nanything else. Just \nsudo iptables-save\n and \nsudo iptables-restore\n to\nrecover them in case something goes awry.\n\n\n\n\nPrerequisites\n#\n\n\nThis is a educational piece of software and has not been tested on\nmany systems yet, to give it a go make sure you have the following:\n\n\n\n\nrecent Linux kernel supporting needed namespaces and cgroups\n\n\noverlayfs \n\n\nip tool (\niproute2 package\n)\n\n\niptables \n\n\ngcc\n\n\nmake\n\n\nbash\n\n\n\n\nOverlayfs is in the mainline kernel so it everything should be\nstraight forward it was merged in version 3.18 but has been improved a\nlot so you should aim for kernel 4.x and in that case you have all the\nnamespaces and cgroups too.\n\n\n\n\nKernel configuration\n\n\nKernel needs to be configured to support following namespaces\nPID, mount, network and UTS, cgroups are needed as well. Most of the\nGNU/Linux distros have this support enabled by default.\n\n\n\n\nInstallation\n#\n\n\n\n\n\n\nmake setup\n\n\nIt creates the necessary directory structure as well as prepares the\nnetworking part like iptables rules, bridge (diyc0) and so on. To\nremove the networking bits like bridge and iptables rules run \nmake\nnet-clean\n which removes them all.\n\n\n\n\n\n\nmake\n\n\nBuilds the runtime.\n\n\n\n\n\n\nDone\n\n\n\n\n\n\nPreparing images\n#\n\n\nThe image import and creation is not present but because images are\njust \nTARBALLS\n there is no need for anything fancy.\n\n\nCreating the tarball using docker\n#\n\n\nUsing docker is the most straightforward. \ndocker pull\n the image you\nwant, spin it up by \ndocker run -ti <image> <command>\n and in\ndifferent terminal do \ndocker export <container> > myimage.tar\n. You\nhave the tarball ready.\n\n\nInstalling image\n#\n\n\nmake setup\n creates an \nimages\n subdirectory so \nmkdir\nimages/myimage\n followed by \ntar -xf myimage.tar -C images/myimage/\n\nshould do the trick. The relation of images and containers is\ndescribed in a section of it's\nown. \nImages and Containers\n.\n\n\n\n\nExample\n\n\nSee \nhow to run a container",
            "title": "Installation"
        },
        {
            "location": "/diyc/install/#getting-started",
            "text": "iptables  diyC plays with iptables to get the routing and isolation running so if\nyou have your own iptables rules make sure to save them before doing\nanything else. Just  sudo iptables-save  and  sudo iptables-restore  to\nrecover them in case something goes awry.",
            "title": "Getting started"
        },
        {
            "location": "/diyc/install/#prerequisites",
            "text": "This is a educational piece of software and has not been tested on\nmany systems yet, to give it a go make sure you have the following:   recent Linux kernel supporting needed namespaces and cgroups  overlayfs   ip tool ( iproute2 package )  iptables   gcc  make  bash   Overlayfs is in the mainline kernel so it everything should be\nstraight forward it was merged in version 3.18 but has been improved a\nlot so you should aim for kernel 4.x and in that case you have all the\nnamespaces and cgroups too.   Kernel configuration  Kernel needs to be configured to support following namespaces\nPID, mount, network and UTS, cgroups are needed as well. Most of the\nGNU/Linux distros have this support enabled by default.",
            "title": "Prerequisites"
        },
        {
            "location": "/diyc/install/#installation",
            "text": "make setup  It creates the necessary directory structure as well as prepares the\nnetworking part like iptables rules, bridge (diyc0) and so on. To\nremove the networking bits like bridge and iptables rules run  make\nnet-clean  which removes them all.    make  Builds the runtime.    Done",
            "title": "Installation"
        },
        {
            "location": "/diyc/install/#preparing-images",
            "text": "The image import and creation is not present but because images are\njust  TARBALLS  there is no need for anything fancy.",
            "title": "Preparing images"
        },
        {
            "location": "/diyc/install/#creating-the-tarball-using-docker",
            "text": "Using docker is the most straightforward.  docker pull  the image you\nwant, spin it up by  docker run -ti <image> <command>  and in\ndifferent terminal do  docker export <container> > myimage.tar . You\nhave the tarball ready.",
            "title": "Creating the tarball using docker"
        },
        {
            "location": "/diyc/install/#installing-image",
            "text": "make setup  creates an  images  subdirectory so  mkdir\nimages/myimage  followed by  tar -xf myimage.tar -C images/myimage/ \nshould do the trick. The relation of images and containers is\ndescribed in a section of it's\nown.  Images and Containers .   Example  See  how to run a container",
            "title": "Installing image"
        },
        {
            "location": "/diyc/usage/",
            "text": "Usage\n#\n\n\n    diyc [hv][-m NUMBER] [-ip IPV4 ADDRESS] <NAME> <IMAGE> <CMD>\n\n    -h, --help           print the help\n\n    -i, --ip             ip address of the container, if not set then host\n                         network is used. It must be in the 172.16.0/16 network\n                         as the bridge diyc0 is 172.16.0.1\n\n    -m, --mem            maximum size of the memory in MB allowed for the container\n                         by default there no explicit limit defined.\n\n    -v, --verbose        more verbose output\n\n    <NAME>               name of the container, needs to be unique\n\n    <IMAGE>              image to be used for the container, must be a directory name\n                         under the images directory\n\n    <CMD>                command to be executed inside the container\n\n\n\n\nExample: Get a container running\n#\n\n\nThis is an example session showing how to get a container with minimal\ndebian based system up and running from zero.\n\n\n$ git clone git@github.com:w-vi/diyc.git\nCloning into 'diyc'...\nremote: Counting objects: 9, done.\nremote: Compressing objects: 100% (8/8), done.\nremote: Total 9 (delta 1), reused 9 (delta 1), pack-reused 0\nReceiving objects: 100% (9/9), 12.95 KiB | 0 bytes/s, done.\nResolving deltas: 100% (1/1), done.\n\n$ cd diyc\n\n$ make setup\nsudo iptables -A FORWARD -i enp5s0 -o veth -j ACCEPT || true\nsudo iptables -A FORWARD -o enp5s0 -i veth -j ACCEPT || true\nsudo iptables -t nat -A POSTROUTING -s 172.16.0.0/16 -j MASQUERADE || true\nsudo ip link add name diyc0 type bridge || true\nsudo ip addr add dev diyc0 172.16.0.1/24 || true\nsudo ip link set diyc0 up || true\nsudo iptables -A FORWARD -i enp5s0 -o diyc0 -j ACCEPT || true\nsudo iptables -A FORWARD -o enp5s0 -i diyc0 -j ACCEPT || true\nsudo iptables -A FORWARD -o diyc0 -i diyc0 -j ACCEPT || true\nmkdir -p containers\nmkdir -p images\n\n$ make\ngcc -std=c99 -Wall -Werror -O2 src/diyc.c -o diyc\ngcc -std=c99 -Wall -Werror -O2 src/nsexec.c -o nsexec\n\n$ docker pull debian\nUsing default tag: latest\nlatest: Pulling from library/debian\nDigest: sha256:72f784399fd2719b4cb4e16ef8e369a39dc67f53d978cd3e2e7bf4e502c7b793\nStatus: Image is up to date for debian:latest\n\n$ docker run -ti debian /bin/bash\n\n$ docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n2c924241399c        debian              \"/bin/bash\"         21 seconds ago      Up 20 seconds                           epic_leavitt\n\n$ docker export 2c924241399c >! debian.tar\n\n$ mkdir images/debian\n\n$ tar -xf debian.tar -C images/debian/\n\n$ sudo ./diyc my1 debian bash\n\n  root@my1:/> exit\n  exit\n\n\n\n\nExample: Network between two containers\n#\n\n\nSpin up two different containers with different IPs. In this case it\nthey are based on debian so Python and curl need to be installed\nfirst.\n\n\n$ sudo ./diyc -i 172.16.0.30 server debian bash\nroot@server:/> apt-get update && apt-get install python\nroot@server:/> python -m SimpleHTTPServer\nServing HTTP on 0.0.0.0 port 8000 ...\n\n$ sudo ./diyc -i 172.16.0.31 client debian bash\nroot@client:/> apt-get update && apt-get install curl\nroot@client:/> curl http://172.16.0.30:8000\n\n# it is accessible from the host too\n$ curl http://172.16.0.30:8000\n\n\n\n\nExample: Limit memory used by cgroups\n#\n\n\nHaving an image with python or perl installed you can easily see the\nOOM killer in action. We will allow only 10 MB of memory.\n\n\n$ sudo ./diyc -m 10 cgroup debian bash\nroot@cgroup:/> python -c 'str = \" \" * 100000'\nroot@cgroup:/> python -c 'str = \" \" * 1000000'\nroot@cgroup:/> python -c 'str = \" \" * 10000000'\nKilled\n\n\n\n\nRemoving exited containers\n#\n\n\nBecause containers after exit leave their filesystem behind and it is\nnot destroyed you can run it again. The data are stored in the\n\ncontainers/<name>/\n directory so as long as this directory exists you\ncan start and stop the container. To remove it just \nsudo rm -rf\ncontainers/<name>\n.\n\n\nRemoving the diyc0 bridge and iptables rules\n#\n\n\nJust run \nmake net-clean\n.",
            "title": "Running containers"
        },
        {
            "location": "/diyc/usage/#usage",
            "text": "diyc [hv][-m NUMBER] [-ip IPV4 ADDRESS] <NAME> <IMAGE> <CMD>\n\n    -h, --help           print the help\n\n    -i, --ip             ip address of the container, if not set then host\n                         network is used. It must be in the 172.16.0/16 network\n                         as the bridge diyc0 is 172.16.0.1\n\n    -m, --mem            maximum size of the memory in MB allowed for the container\n                         by default there no explicit limit defined.\n\n    -v, --verbose        more verbose output\n\n    <NAME>               name of the container, needs to be unique\n\n    <IMAGE>              image to be used for the container, must be a directory name\n                         under the images directory\n\n    <CMD>                command to be executed inside the container",
            "title": "Usage"
        },
        {
            "location": "/diyc/usage/#example-get-a-container-running",
            "text": "This is an example session showing how to get a container with minimal\ndebian based system up and running from zero.  $ git clone git@github.com:w-vi/diyc.git\nCloning into 'diyc'...\nremote: Counting objects: 9, done.\nremote: Compressing objects: 100% (8/8), done.\nremote: Total 9 (delta 1), reused 9 (delta 1), pack-reused 0\nReceiving objects: 100% (9/9), 12.95 KiB | 0 bytes/s, done.\nResolving deltas: 100% (1/1), done.\n\n$ cd diyc\n\n$ make setup\nsudo iptables -A FORWARD -i enp5s0 -o veth -j ACCEPT || true\nsudo iptables -A FORWARD -o enp5s0 -i veth -j ACCEPT || true\nsudo iptables -t nat -A POSTROUTING -s 172.16.0.0/16 -j MASQUERADE || true\nsudo ip link add name diyc0 type bridge || true\nsudo ip addr add dev diyc0 172.16.0.1/24 || true\nsudo ip link set diyc0 up || true\nsudo iptables -A FORWARD -i enp5s0 -o diyc0 -j ACCEPT || true\nsudo iptables -A FORWARD -o enp5s0 -i diyc0 -j ACCEPT || true\nsudo iptables -A FORWARD -o diyc0 -i diyc0 -j ACCEPT || true\nmkdir -p containers\nmkdir -p images\n\n$ make\ngcc -std=c99 -Wall -Werror -O2 src/diyc.c -o diyc\ngcc -std=c99 -Wall -Werror -O2 src/nsexec.c -o nsexec\n\n$ docker pull debian\nUsing default tag: latest\nlatest: Pulling from library/debian\nDigest: sha256:72f784399fd2719b4cb4e16ef8e369a39dc67f53d978cd3e2e7bf4e502c7b793\nStatus: Image is up to date for debian:latest\n\n$ docker run -ti debian /bin/bash\n\n$ docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n2c924241399c        debian              \"/bin/bash\"         21 seconds ago      Up 20 seconds                           epic_leavitt\n\n$ docker export 2c924241399c >! debian.tar\n\n$ mkdir images/debian\n\n$ tar -xf debian.tar -C images/debian/\n\n$ sudo ./diyc my1 debian bash\n\n  root@my1:/> exit\n  exit",
            "title": "Example: Get a container running"
        },
        {
            "location": "/diyc/usage/#example-network-between-two-containers",
            "text": "Spin up two different containers with different IPs. In this case it\nthey are based on debian so Python and curl need to be installed\nfirst.  $ sudo ./diyc -i 172.16.0.30 server debian bash\nroot@server:/> apt-get update && apt-get install python\nroot@server:/> python -m SimpleHTTPServer\nServing HTTP on 0.0.0.0 port 8000 ...\n\n$ sudo ./diyc -i 172.16.0.31 client debian bash\nroot@client:/> apt-get update && apt-get install curl\nroot@client:/> curl http://172.16.0.30:8000\n\n# it is accessible from the host too\n$ curl http://172.16.0.30:8000",
            "title": "Example: Network between two containers"
        },
        {
            "location": "/diyc/usage/#example-limit-memory-used-by-cgroups",
            "text": "Having an image with python or perl installed you can easily see the\nOOM killer in action. We will allow only 10 MB of memory.  $ sudo ./diyc -m 10 cgroup debian bash\nroot@cgroup:/> python -c 'str = \" \" * 100000'\nroot@cgroup:/> python -c 'str = \" \" * 1000000'\nroot@cgroup:/> python -c 'str = \" \" * 10000000'\nKilled",
            "title": "Example: Limit memory used by cgroups"
        },
        {
            "location": "/diyc/usage/#removing-exited-containers",
            "text": "Because containers after exit leave their filesystem behind and it is\nnot destroyed you can run it again. The data are stored in the containers/<name>/  directory so as long as this directory exists you\ncan start and stop the container. To remove it just  sudo rm -rf\ncontainers/<name> .",
            "title": "Removing exited containers"
        },
        {
            "location": "/diyc/usage/#removing-the-diyc0-bridge-and-iptables-rules",
            "text": "Just run  make net-clean .",
            "title": "Removing the diyc0 bridge and iptables rules"
        }
    ]
}