{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Linux containers from scratch - diyC # Linux containers exist for a while and are now a mainstream topic. This is an introduction on how they are created and what they actually are made of. If you want to see the code then head directly to the GitHub repo otherwise read on the topic you are interested in. Note Any suggestions or comments are welcome please don't hesitate and file an issue on GitHub . What is a Linux container # Containers in some form exist for quite while even though we don't always think of them as containers . Linux container to put it simply it is a usual Linux process (or group of processes) with a limited (altered) view of the system. It is achieved by utilizing Operating system level virtualization . Building containers from scratch # Follwing are the kernel features and other bits needed to build containers from scratch. Linux Namespaces Linux cgroups Networking Images and containers One topic which is not covered although it should is capabilities(7) and privilages like low port binding . What is diyC # It is a simple educational Linux container runtime. It is intentionally simple and leaves a lot of stuff out. It is a single C file of roughly 500 lines including comments showing the core features of the Linux used to build containers. It includes also the creation of a container from an image to clarify how images and containers are related. nsexec # Part of the project is also a nsexec binary which is is a very simple program that executes a local (host) command in Linux namespaces. See nsexec --help to see what namespaces are available. Usage is very simple sudo ./nsexec -pnu myhost bash will start a new bash in new pid, network and UTS namespace.","title":"Home"},{"location":"#linux-containers-from-scratch-diyc","text":"Linux containers exist for a while and are now a mainstream topic. This is an introduction on how they are created and what they actually are made of. If you want to see the code then head directly to the GitHub repo otherwise read on the topic you are interested in. Note Any suggestions or comments are welcome please don't hesitate and file an issue on GitHub .","title":"Linux containers from scratch - diyC"},{"location":"#what-is-a-linux-container","text":"Containers in some form exist for quite while even though we don't always think of them as containers . Linux container to put it simply it is a usual Linux process (or group of processes) with a limited (altered) view of the system. It is achieved by utilizing Operating system level virtualization .","title":"What is a Linux container"},{"location":"#building-containers-from-scratch","text":"Follwing are the kernel features and other bits needed to build containers from scratch. Linux Namespaces Linux cgroups Networking Images and containers One topic which is not covered although it should is capabilities(7) and privilages like low port binding .","title":"Building containers from scratch"},{"location":"#what-is-diyc","text":"It is a simple educational Linux container runtime. It is intentionally simple and leaves a lot of stuff out. It is a single C file of roughly 500 lines including comments showing the core features of the Linux used to build containers. It includes also the creation of a container from an image to clarify how images and containers are related.","title":"What is diyC"},{"location":"#nsexec","text":"Part of the project is also a nsexec binary which is is a very simple program that executes a local (host) command in Linux namespaces. See nsexec --help to see what namespaces are available. Usage is very simple sudo ./nsexec -pnu myhost bash will start a new bash in new pid, network and UTS namespace.","title":"nsexec"},{"location":"cgroups/","text":"Linux cgroups a.k.a. Control Groups # Without setting limits on resources the isolation of containers doesn't work well because a rogue container can eat up all the memory or file descriptors of the host system and thus bring everything down. We can use usual limits getrlimit(2) to achieve something but it is far from enough and brings issues because of UIDs mappings, capabilities and so on. Cgroups # Cgroups is a Linux kernel feature to limit, police and account the resource usage for a set of processes and containers are just that. Cgroups are hierarchical and child cgroups inherit certain attributes from their parent cgroup and cannot override those set by parent. Every process or thread belongs to one cgroup in given subsystem. There are actually two versions of the implementation v1 and v2 where the main difference is that v1 operates on thread level but v2 is simpler and considers only processes. Cgroup subsystems # Some of the subsystems are listed here see Fedora Resource Management Guide for all the details. blkio - limits on IO cpu - cpu scheduling cpuset - assigns CPU(s)n on multicore systems devices - controls access to devices memory - memory limits like rss, swap etc. Managing cgroups # Cgroups have no syscalls but are managed through a filesystem under /sys/fs/cgroup where each of the subsystem is directory. It is very easy to create a new group in any of the subsystems just create subdirectory and kernel will populate it with the files. $ mkdir /sys/fs/cgroup/memory/mygroup $ ls -la /sys/fs/cgroup/memory/mygroup total 0 drwxr-xr-x 2 root root 0 28.04.2017 13:05 ./ dr-xr-xr-x 6 root root 0 28.04.2017 13:03 ../ -rw-r--r-- 1 root root 0 28.04.2017 13:05 cgroup.clone_children --w--w--w- 1 root root 0 28.04.2017 13:05 cgroup.event_control -rw-r--r-- 1 root root 0 28.04.2017 13:05 cgroup.procs -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.failcnt --w------- 1 root root 0 28.04.2017 13:05 memory.force_empty -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.failcnt -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.limit_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.max_usage_in_bytes -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.slabinfo -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.failcnt -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.limit_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.max_usage_in_bytes -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.usage_in_bytes -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.usage_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.limit_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.max_usage_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.failcnt -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.limit_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.max_usage_in_bytes -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.usage_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.move_charge_at_immigrate -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.numa_stat -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.oom_control ---------- 1 root root 0 28.04.2017 13:05 memory.pressure_level -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.soft_limit_in_bytes -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.stat -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.swappiness -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.usage_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.use_hierarchy -rw-r--r-- 1 root root 0 28.04.2017 13:05 notify_on_release -rw-r--r-- 1 root root 0 28.04.2017 13:05 tasks Now we can set a memory limit to 10 MB for this group. $ echo 1000000 > /sys/fs/cgroup/memory/mygroup/memory.limit_in_bytes To add a process to our group we need to just append the pid to cgroup.procs file. echo $$ > /sys/fs/cgroup/memory/groupname/cgroup.procs The shell and it's children are now limited to 10MB which you can easily check by allocation enough memory. Use rmdir to remove the group. The group cannot be removed untill there are no processes running in that group. Code The cgroup and limits are set up after the clone when the pid of the container is known. diyc.c:204-262 Example using diyc More to read # Linux kernel cgroups v1 Linux kernel cgroups v2 Control groups on Ubuntu Server Guide RHEL Resource Management Guide","title":"Linux Cgroups"},{"location":"cgroups/#linux-cgroups-aka-control-groups","text":"Without setting limits on resources the isolation of containers doesn't work well because a rogue container can eat up all the memory or file descriptors of the host system and thus bring everything down. We can use usual limits getrlimit(2) to achieve something but it is far from enough and brings issues because of UIDs mappings, capabilities and so on.","title":"Linux cgroups a.k.a. Control Groups"},{"location":"cgroups/#cgroups","text":"Cgroups is a Linux kernel feature to limit, police and account the resource usage for a set of processes and containers are just that. Cgroups are hierarchical and child cgroups inherit certain attributes from their parent cgroup and cannot override those set by parent. Every process or thread belongs to one cgroup in given subsystem. There are actually two versions of the implementation v1 and v2 where the main difference is that v1 operates on thread level but v2 is simpler and considers only processes.","title":"Cgroups"},{"location":"cgroups/#cgroup-subsystems","text":"Some of the subsystems are listed here see Fedora Resource Management Guide for all the details. blkio - limits on IO cpu - cpu scheduling cpuset - assigns CPU(s)n on multicore systems devices - controls access to devices memory - memory limits like rss, swap etc.","title":"Cgroup subsystems"},{"location":"cgroups/#managing-cgroups","text":"Cgroups have no syscalls but are managed through a filesystem under /sys/fs/cgroup where each of the subsystem is directory. It is very easy to create a new group in any of the subsystems just create subdirectory and kernel will populate it with the files. $ mkdir /sys/fs/cgroup/memory/mygroup $ ls -la /sys/fs/cgroup/memory/mygroup total 0 drwxr-xr-x 2 root root 0 28.04.2017 13:05 ./ dr-xr-xr-x 6 root root 0 28.04.2017 13:03 ../ -rw-r--r-- 1 root root 0 28.04.2017 13:05 cgroup.clone_children --w--w--w- 1 root root 0 28.04.2017 13:05 cgroup.event_control -rw-r--r-- 1 root root 0 28.04.2017 13:05 cgroup.procs -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.failcnt --w------- 1 root root 0 28.04.2017 13:05 memory.force_empty -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.failcnt -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.limit_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.max_usage_in_bytes -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.slabinfo -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.failcnt -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.limit_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.max_usage_in_bytes -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.tcp.usage_in_bytes -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.kmem.usage_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.limit_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.max_usage_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.failcnt -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.limit_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.max_usage_in_bytes -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.memsw.usage_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.move_charge_at_immigrate -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.numa_stat -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.oom_control ---------- 1 root root 0 28.04.2017 13:05 memory.pressure_level -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.soft_limit_in_bytes -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.stat -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.swappiness -r--r--r-- 1 root root 0 28.04.2017 13:05 memory.usage_in_bytes -rw-r--r-- 1 root root 0 28.04.2017 13:05 memory.use_hierarchy -rw-r--r-- 1 root root 0 28.04.2017 13:05 notify_on_release -rw-r--r-- 1 root root 0 28.04.2017 13:05 tasks Now we can set a memory limit to 10 MB for this group. $ echo 1000000 > /sys/fs/cgroup/memory/mygroup/memory.limit_in_bytes To add a process to our group we need to just append the pid to cgroup.procs file. echo $$ > /sys/fs/cgroup/memory/groupname/cgroup.procs The shell and it's children are now limited to 10MB which you can easily check by allocation enough memory. Use rmdir to remove the group. The group cannot be removed untill there are no processes running in that group. Code The cgroup and limits are set up after the clone when the pid of the container is known. diyc.c:204-262 Example using diyc","title":"Managing cgroups"},{"location":"cgroups/#more-to-read","text":"Linux kernel cgroups v1 Linux kernel cgroups v2 Control groups on Ubuntu Server Guide RHEL Resource Management Guide","title":"More to read"},{"location":"glue/","text":"Putting it together # Putting Linux features together to create a container. This section covers how the containers are actually created using all those Linux features mentioned.","title":"Putting it together"},{"location":"glue/#putting-it-together","text":"Putting Linux features together to create a container. This section covers how the containers are actually created using all those Linux features mentioned.","title":"Putting it together"},{"location":"images-containers/","text":"Images and Containers # This section covers how the container is created from an image. What is an image? # Container images are basically just tarballs or tarballs of tarballs. The tarball contains files and directories needed by the program running in the container. A very simple way how to inspect an image is to export it using docker. Spin the desired container up, in this case a base debian image. $ docker run -ti debian bash In other terminal, find the container and export it. $ docker ps CONTAINER ID IMAGE COMMAND f222a193be90 debian \"bash\" $ docker export f222a193be90 > deian.tar Stop the container root@f222a193be90:/> exit Untar the image into directory. $ mkdir debain-image $ tar -xf debian.tar -C debian-image Inspect what's inside. It looks like a usual GNU/Linux filesystem layout. $ ls -la debian-image total 92 drwxr-xr-x 21 wvi wvi 4096 23.04.2017 11:07 ./ drwxrwxrwx 113 wvi wvi 12288 23.04.2017 11:07 ../ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:29 bin/ drwxr-xr-x 2 wvi wvi 4096 28.12.2016 18:42 boot/ drwxr-xr-x 4 wvi wvi 4096 23.04.2017 11:00 dev/ drwxr-xr-x 41 wvi wvi 4096 23.04.2017 11:00 etc/ drwxr-xr-x 2 wvi wvi 4096 28.12.2016 18:42 home/ drwxr-xr-x 9 wvi wvi 4096 27.11.2014 20:59 lib/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:27 lib64/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:26 media/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:26 mnt/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:26 opt/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:29 proc/ drwx------ 2 wvi wvi 4096 21.03.2017 00:26 root/ drwxr-xr-x 3 wvi wvi 4096 21.03.2017 00:26 run/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:29 sbin/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:26 srv/ drwxr-xr-x 2 wvi wvi 4096 06.04.2015 20:44 sys/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:29 tmp/ drwxr-xr-x 10 wvi wvi 4096 21.03.2017 00:26 usr/ drwxr-xr-x 11 wvi wvi 4096 21.03.2017 00:26 var/ -rwxr-xr-x 1 wvi wvi 0 23.04.2017 11:00 .dockerenv* Creating the image # To create an image for the diyC the easiest is to export the docker image . Generally for containers there are many other ways how to create an image but it is out of scope of this project so here is just a few pointers. Statically linked programs where you need just that one binary nothing else so something along those lines should suffice. That's for example what you can do with Go programs . $ mkdir image $ cp <my-statically-linked-binary> image $ tar -cf image.tar image https://buildroot.org/ is a toolbox for creating embedded Linux systems but you can very easily create a custom installation which will be very small. See a great talk on this topic from Brian \"Redbeard\" Harrington from coreOS . Get your filesystem layout and copy files needed. you can use package managers like dnf , yum , debootsrap etc. and tar the structure up. Easy way to verify that the tarball makes sense is to import it to docker using docker import tarball.tar . How a container is created from an image? # The main magic is layers because containers are like Ogres . The container's filesystem is usually made of at least two layers many times there are more layers involved but that doesn't change the core concept where one layer is the image and the other is a writable temporary directory for the container to write files so that the image remains immutable. To achieve such behavior you need a so called union mount which basically mounts a new filesystem combining two or more directories/filesystems together into one. Above: Simplified unioning filesystem scheme Such a unified filesystem is then mounted under some temp working directory and in the container it is changed to be the root filesystem using the pivot_root syscall . pivot_root is almost like a chroot but you get to keep access to the original old root so you can for example copy some configuration files to the new root. Code See the implementation in diy.c:335-361 Very similar behavior is also possible using completely different approaches, i.e utilizing subvolumes and snapshots of btrfs or using devicemapper . Docker uses devicemapper approach on many systems by default and has a very good description of the devicemapper approach . Unioning filesystems in Linux # Historically there were couple of options on Linux but only one of them ended up in the mainline kernel. Describing the history and details is out of the scope but the main ones are : UnionFS aufs overlayFS Today the easiest option is to use overlayfs filesystem because it was merged to mainline kernel in version 3.18. It is actually called overlay since the merge. To check if you are able to use it see /proc/filesystems file ( man 5 filesystems ). overlay kernel module Very often it does not show up in the /proc/filesystems because it is loaded only if it is used so try modprobe overlay to load the kernel module. Using overlay filesystem # In the overlayfs there are two layers, lowerdir which is always read only and upperdir which is writable. You can actually have more lowerdir directories which are all read only as any changes are always stored in the upperdir . It can be used in many ways (i.e. Live CDs) and is not specific to containers. You can give it a try yourself easily from a command line. Overlay mount(8) options. # mount -t overlay overlay -o lowerdir=/lower1:/lower2,upperdir=/upper,workdir=/work /merged workdir The workdir parameter must be on the same filesystem as the upperdir directory and it is used for certain atomic operations. lowerdir can be on a different filesystem though. # In tmp create the needed directory structure $ mkdir /tmp/lower /tmp/upper /tmp/workdir /tmp/merged # and mount an overlay fs $ sudo mount -t overlay -o \\ lowerdir=/tmp/lower,\\ upperdir=/tmp/upper,\\ workdir=/tmp/workdir \\ none /tmp/merged If you play around creating/writing/deleting files and directories in the lower , upper and merged you can observe the following. Observations # If there are directories in both lower and upper their content is merged. Files created in the lower or upper directory are visible in the merged . Any files created in the merged are actually created in the upper . Writing to existing files appears again only in upper even if the file was originally in lower , the file is copied up . Deleting a file or directory in merged that was in the lower , removes it from merged but not lower . It creates a so called \"whiteout\" file/directory in the upper . Container filesystem is created in the same fashion, image is the lowerdir and container specific files are in the upperdir . Inside the container you see the merged . More to read # Overlay documentation in kernel Docker and OverlayFS in practice Docker and the Device Mapper storage driver Unioning file systems: Architecture, features, and design choices Union file systems: Implementations, part I Unioning file systems: Implementations, part 2 Another union filesystem approach","title":"Images and containers"},{"location":"images-containers/#images-and-containers","text":"This section covers how the container is created from an image.","title":"Images and Containers"},{"location":"images-containers/#what-is-an-image","text":"Container images are basically just tarballs or tarballs of tarballs. The tarball contains files and directories needed by the program running in the container. A very simple way how to inspect an image is to export it using docker. Spin the desired container up, in this case a base debian image. $ docker run -ti debian bash In other terminal, find the container and export it. $ docker ps CONTAINER ID IMAGE COMMAND f222a193be90 debian \"bash\" $ docker export f222a193be90 > deian.tar Stop the container root@f222a193be90:/> exit Untar the image into directory. $ mkdir debain-image $ tar -xf debian.tar -C debian-image Inspect what's inside. It looks like a usual GNU/Linux filesystem layout. $ ls -la debian-image total 92 drwxr-xr-x 21 wvi wvi 4096 23.04.2017 11:07 ./ drwxrwxrwx 113 wvi wvi 12288 23.04.2017 11:07 ../ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:29 bin/ drwxr-xr-x 2 wvi wvi 4096 28.12.2016 18:42 boot/ drwxr-xr-x 4 wvi wvi 4096 23.04.2017 11:00 dev/ drwxr-xr-x 41 wvi wvi 4096 23.04.2017 11:00 etc/ drwxr-xr-x 2 wvi wvi 4096 28.12.2016 18:42 home/ drwxr-xr-x 9 wvi wvi 4096 27.11.2014 20:59 lib/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:27 lib64/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:26 media/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:26 mnt/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:26 opt/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:29 proc/ drwx------ 2 wvi wvi 4096 21.03.2017 00:26 root/ drwxr-xr-x 3 wvi wvi 4096 21.03.2017 00:26 run/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:29 sbin/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:26 srv/ drwxr-xr-x 2 wvi wvi 4096 06.04.2015 20:44 sys/ drwxr-xr-x 2 wvi wvi 4096 21.03.2017 00:29 tmp/ drwxr-xr-x 10 wvi wvi 4096 21.03.2017 00:26 usr/ drwxr-xr-x 11 wvi wvi 4096 21.03.2017 00:26 var/ -rwxr-xr-x 1 wvi wvi 0 23.04.2017 11:00 .dockerenv*","title":"What is an image?"},{"location":"images-containers/#creating-the-image","text":"To create an image for the diyC the easiest is to export the docker image . Generally for containers there are many other ways how to create an image but it is out of scope of this project so here is just a few pointers. Statically linked programs where you need just that one binary nothing else so something along those lines should suffice. That's for example what you can do with Go programs . $ mkdir image $ cp <my-statically-linked-binary> image $ tar -cf image.tar image https://buildroot.org/ is a toolbox for creating embedded Linux systems but you can very easily create a custom installation which will be very small. See a great talk on this topic from Brian \"Redbeard\" Harrington from coreOS . Get your filesystem layout and copy files needed. you can use package managers like dnf , yum , debootsrap etc. and tar the structure up. Easy way to verify that the tarball makes sense is to import it to docker using docker import tarball.tar .","title":"Creating the image"},{"location":"images-containers/#how-a-container-is-created-from-an-image","text":"The main magic is layers because containers are like Ogres . The container's filesystem is usually made of at least two layers many times there are more layers involved but that doesn't change the core concept where one layer is the image and the other is a writable temporary directory for the container to write files so that the image remains immutable. To achieve such behavior you need a so called union mount which basically mounts a new filesystem combining two or more directories/filesystems together into one. Above: Simplified unioning filesystem scheme Such a unified filesystem is then mounted under some temp working directory and in the container it is changed to be the root filesystem using the pivot_root syscall . pivot_root is almost like a chroot but you get to keep access to the original old root so you can for example copy some configuration files to the new root. Code See the implementation in diy.c:335-361 Very similar behavior is also possible using completely different approaches, i.e utilizing subvolumes and snapshots of btrfs or using devicemapper . Docker uses devicemapper approach on many systems by default and has a very good description of the devicemapper approach .","title":"How a container is created from an image?"},{"location":"images-containers/#unioning-filesystems-in-linux","text":"Historically there were couple of options on Linux but only one of them ended up in the mainline kernel. Describing the history and details is out of the scope but the main ones are : UnionFS aufs overlayFS Today the easiest option is to use overlayfs filesystem because it was merged to mainline kernel in version 3.18. It is actually called overlay since the merge. To check if you are able to use it see /proc/filesystems file ( man 5 filesystems ). overlay kernel module Very often it does not show up in the /proc/filesystems because it is loaded only if it is used so try modprobe overlay to load the kernel module.","title":"Unioning filesystems in Linux"},{"location":"images-containers/#using-overlay-filesystem","text":"In the overlayfs there are two layers, lowerdir which is always read only and upperdir which is writable. You can actually have more lowerdir directories which are all read only as any changes are always stored in the upperdir . It can be used in many ways (i.e. Live CDs) and is not specific to containers. You can give it a try yourself easily from a command line. Overlay mount(8) options. # mount -t overlay overlay -o lowerdir=/lower1:/lower2,upperdir=/upper,workdir=/work /merged workdir The workdir parameter must be on the same filesystem as the upperdir directory and it is used for certain atomic operations. lowerdir can be on a different filesystem though. # In tmp create the needed directory structure $ mkdir /tmp/lower /tmp/upper /tmp/workdir /tmp/merged # and mount an overlay fs $ sudo mount -t overlay -o \\ lowerdir=/tmp/lower,\\ upperdir=/tmp/upper,\\ workdir=/tmp/workdir \\ none /tmp/merged If you play around creating/writing/deleting files and directories in the lower , upper and merged you can observe the following.","title":"Using overlay filesystem"},{"location":"images-containers/#observations","text":"If there are directories in both lower and upper their content is merged. Files created in the lower or upper directory are visible in the merged . Any files created in the merged are actually created in the upper . Writing to existing files appears again only in upper even if the file was originally in lower , the file is copied up . Deleting a file or directory in merged that was in the lower , removes it from merged but not lower . It creates a so called \"whiteout\" file/directory in the upper . Container filesystem is created in the same fashion, image is the lowerdir and container specific files are in the upperdir . Inside the container you see the merged .","title":"Observations"},{"location":"images-containers/#more-to-read","text":"Overlay documentation in kernel Docker and OverlayFS in practice Docker and the Device Mapper storage driver Unioning file systems: Architecture, features, and design choices Union file systems: Implementations, part I Unioning file systems: Implementations, part 2 Another union filesystem approach","title":"More to read"},{"location":"namespaces/","text":"Linux Namespaces # This section covers how the containers are isolated from the host as well as each other using the kernel namespaces. This is actually the most significant kernel feature which virtualizes the resources and isolates the processes from each other and using just namespaces creates a containers of sorts, see nsexec . Namespaces # Pasting here the definition from the manual page namespaces(7) as there probably isn't a better one. A namespace wraps a global system resource in an abstraction that makes it appear to the processes within the namespace that they have their own isolated instance of the global resource. Changes to the global resource are visible to other processes that are members of the namespace, but are invisible to other processes. There are 7 namespaces at the moment and a process can be in one or more of them. There are always global namespaces for each of the types so that any process is always in some namespace of each type. Linux has so far following namespaces. Number in the brackets is the kernel version when the namespace was introduced Mount (2.4.19) Isolates the mount points. A process has it's own view of the mount points and changes are not propagated to other namespaces. mount_namespaces(7) UTS (2.6.19) Isolates the hostname and the NIS domain name. Calling sethostname(2) or setdomainname(2) is affecting only the namespace. IPC (2.6.19) Isolates IPC resources. System V IPC objects and POSIX message queues. PID (2.6.24) Isolates the process ID number space. Processes in different PID namespaces can have the same PID or can't see PIDs of different namespace. pid_namespaces(7) Network (2.6.29) Isolates the network resources like network devices, IPv4 and IPv6 protocol stacks, IP routing tables, firewalls etc. User (3.8) Isolates the user and group resources, unprivileged user in the \"root\" namespace can be a user ID 0 in the new namespace. When new user namespace is created the user gets full capabilities(7) inside the namespace. user_namespaces(7) Cgroups (4.6) Isolates the view of the /proc/[pid]/cgroup and /proc/[pid]/mountinfo . cgroup_namespaces(7) Mount namespace # Mount namespace isolates the mount points and effectively different namespaces can have different filesystem trees as well as any changes in the mount points may or may not be propagated in the other namespaces depending on the mount types (private, bind, slave etc), see mount(8) . In the container context it means that anything happening to mount points inside the container is not propagated elsewhere so they are completely isolated. Image courtesy of Wonchang Song PID namespace # PID namespace isolated the PID numbers, they are a hierarchical structure where the parent namespace can view all the PIDs in the child namespaces. When a new namespace is created the first process gets the PID 1 and is a sort of init process of that namespace. It should in the ideal world be able to reap any child processes as otherwise it can actually exhaust the root PID space because of the hierarchical nature. Network namespace # Network namespace creates a completely new network stack including routing tables, in a new network namespace you get just the loopback device lo and nothing else so you are actually unable to connect to the network (see nsexec ). Physical network interfaces can reside in only one namespace at a time so very often to connect the namespace somewhere the virtual Ethernet device pair ( veth pair ) is used with together with Linux bridge . In any case the setns(2) comes handy for adding a device to the namespace. Creating new namespaces # There are two syscalls how to create a new namespace. clone(2) is like fork(2) but allows you to pick what context you share with the parent process. unshare(2) is to disassociate from the parent process context and thus create a new one. There is also setns(2) which allows you to enter an existing namespace. unshare and nsenter in the shell # You can play with the namespaces in the shell too, nsenter(1) is the command line equivalent of setns(2) and unshare(1) is the equivalent of unshare(2) syscall. $ unshare --fork --pid --mount-proc Runs a new shell in own PID namespace, it needs to remount the procfs as otherwise tools like ps would still show the parent namespace. nsexec # nsexec is a minimal example on how to use namespaces to isolate processes and one could argue that it creates a container using the host filesystem and programs. ./nsexec --help Create a child process that executes a shell command in new namespace(s), Usage: ./nsexec [OPTIONS] <CMD> -h, --help print this help -n, --net new network namespace -p, --pid new PID namespace -u, --uts HOSTNAME new UTS namespace -v, --verbose more verbose output <CMD> command to be executed See the Code nsexec.c Example # $ sudo ./nsexec -npu myhost bash myhost> ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 10:45 pts/3 00:00:00 bash root 6 1 0 10:45 pts/3 00:00:00 ps -ef myhost> ip a 1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 myhost> exit exit More to read # Namespaces in operation, part 1: namespaces overview Applying mount namespaces Introducing Linux Network Namespaces A Follow Up on Linux Network Namespaces","title":"Linux Namespaces"},{"location":"namespaces/#linux-namespaces","text":"This section covers how the containers are isolated from the host as well as each other using the kernel namespaces. This is actually the most significant kernel feature which virtualizes the resources and isolates the processes from each other and using just namespaces creates a containers of sorts, see nsexec .","title":"Linux Namespaces"},{"location":"namespaces/#namespaces","text":"Pasting here the definition from the manual page namespaces(7) as there probably isn't a better one. A namespace wraps a global system resource in an abstraction that makes it appear to the processes within the namespace that they have their own isolated instance of the global resource. Changes to the global resource are visible to other processes that are members of the namespace, but are invisible to other processes. There are 7 namespaces at the moment and a process can be in one or more of them. There are always global namespaces for each of the types so that any process is always in some namespace of each type. Linux has so far following namespaces. Number in the brackets is the kernel version when the namespace was introduced Mount (2.4.19) Isolates the mount points. A process has it's own view of the mount points and changes are not propagated to other namespaces. mount_namespaces(7) UTS (2.6.19) Isolates the hostname and the NIS domain name. Calling sethostname(2) or setdomainname(2) is affecting only the namespace. IPC (2.6.19) Isolates IPC resources. System V IPC objects and POSIX message queues. PID (2.6.24) Isolates the process ID number space. Processes in different PID namespaces can have the same PID or can't see PIDs of different namespace. pid_namespaces(7) Network (2.6.29) Isolates the network resources like network devices, IPv4 and IPv6 protocol stacks, IP routing tables, firewalls etc. User (3.8) Isolates the user and group resources, unprivileged user in the \"root\" namespace can be a user ID 0 in the new namespace. When new user namespace is created the user gets full capabilities(7) inside the namespace. user_namespaces(7) Cgroups (4.6) Isolates the view of the /proc/[pid]/cgroup and /proc/[pid]/mountinfo . cgroup_namespaces(7)","title":"Namespaces"},{"location":"namespaces/#mount-namespace","text":"Mount namespace isolates the mount points and effectively different namespaces can have different filesystem trees as well as any changes in the mount points may or may not be propagated in the other namespaces depending on the mount types (private, bind, slave etc), see mount(8) . In the container context it means that anything happening to mount points inside the container is not propagated elsewhere so they are completely isolated. Image courtesy of Wonchang Song","title":"Mount namespace"},{"location":"namespaces/#pid-namespace","text":"PID namespace isolated the PID numbers, they are a hierarchical structure where the parent namespace can view all the PIDs in the child namespaces. When a new namespace is created the first process gets the PID 1 and is a sort of init process of that namespace. It should in the ideal world be able to reap any child processes as otherwise it can actually exhaust the root PID space because of the hierarchical nature.","title":"PID namespace"},{"location":"namespaces/#network-namespace","text":"Network namespace creates a completely new network stack including routing tables, in a new network namespace you get just the loopback device lo and nothing else so you are actually unable to connect to the network (see nsexec ). Physical network interfaces can reside in only one namespace at a time so very often to connect the namespace somewhere the virtual Ethernet device pair ( veth pair ) is used with together with Linux bridge . In any case the setns(2) comes handy for adding a device to the namespace.","title":"Network namespace"},{"location":"namespaces/#creating-new-namespaces","text":"There are two syscalls how to create a new namespace. clone(2) is like fork(2) but allows you to pick what context you share with the parent process. unshare(2) is to disassociate from the parent process context and thus create a new one. There is also setns(2) which allows you to enter an existing namespace.","title":"Creating new namespaces"},{"location":"namespaces/#unshare-and-nsenter-in-the-shell","text":"You can play with the namespaces in the shell too, nsenter(1) is the command line equivalent of setns(2) and unshare(1) is the equivalent of unshare(2) syscall. $ unshare --fork --pid --mount-proc Runs a new shell in own PID namespace, it needs to remount the procfs as otherwise tools like ps would still show the parent namespace.","title":"unshare and nsenter in the shell"},{"location":"namespaces/#nsexec","text":"nsexec is a minimal example on how to use namespaces to isolate processes and one could argue that it creates a container using the host filesystem and programs. ./nsexec --help Create a child process that executes a shell command in new namespace(s), Usage: ./nsexec [OPTIONS] <CMD> -h, --help print this help -n, --net new network namespace -p, --pid new PID namespace -u, --uts HOSTNAME new UTS namespace -v, --verbose more verbose output <CMD> command to be executed See the Code nsexec.c","title":"nsexec"},{"location":"namespaces/#example","text":"$ sudo ./nsexec -npu myhost bash myhost> ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 10:45 pts/3 00:00:00 bash root 6 1 0 10:45 pts/3 00:00:00 ps -ef myhost> ip a 1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 myhost> exit exit","title":"Example"},{"location":"namespaces/#more-to-read","text":"Namespaces in operation, part 1: namespaces overview Applying mount namespaces Introducing Linux Network Namespaces A Follow Up on Linux Network Namespaces","title":"More to read"},{"location":"networking/","text":"Containers and networking # Containers without network access are in many cases pretty useless. If the container should not share network resources with the host that is has it's own network namespace we need to connect it somehow because by default new network namespace has only loop device, you can add the network device to a namespace but it can reside only in one of them. Considering dozens of containers on a single host we are not going to have enough physical interfaces. Virtual Ethernet devices # In Linux you can create virtual Ethernet devices, they come in pairs, a so called veth pair, which you can think of as two Ethernet cards connected by a cable. using ip tool you can easily assign one of the pair to the container's namespace and the other somewhere else. Ideally to Linux bridge or Open vSwitch so we can create virtual networks. Connecting containers using bridge # Using the Linux bridge is the easiest, we create the bridge which we call here diyc0 and assign it IPv4 address 172.16.0.1/24 . # Create the bridge $ ip link add name diyc0 type bridge # Assign it IPv4 $ ip addr add dev diyc0 172.16.0.1/24 $ ip link set diyc0 up Before we run the container we connect the created vethXYZ device to the bridge that's the host half of the pair. The other one is later added to the network namespace of the container, effectively connecting the two namespace. # Create the veth pair $ ip link add vethXYZ type veth peer name veth1 # Connect the host half to bridge $ ip link set vethXYZ master diyc0 # Add the veth1 to the container's network namespace # <PID> is pid of the container process $ ip link set veth1 netns <PID> Below: Connecting containers using veth pairs and Linux bridge Code Code in diyC uses system() function to shell out so you can easily replicate it on the command line. diyc.c:265-302 iptables # Once the containers are hooked up using veth pairs and a bridge it comes to iptables to do NAT and routing to allow containers to connect to the outer world. See the net-setup code in the Makefile to inspect the exact rules. Basically setup NAT and forwarding on the container network in our case 172.16.0.0/16 . More to read # Linux Switching \u2013 Interconnecting Namespaces Linux Network Namespaces","title":"Networking"},{"location":"networking/#containers-and-networking","text":"Containers without network access are in many cases pretty useless. If the container should not share network resources with the host that is has it's own network namespace we need to connect it somehow because by default new network namespace has only loop device, you can add the network device to a namespace but it can reside only in one of them. Considering dozens of containers on a single host we are not going to have enough physical interfaces.","title":"Containers and networking"},{"location":"networking/#virtual-ethernet-devices","text":"In Linux you can create virtual Ethernet devices, they come in pairs, a so called veth pair, which you can think of as two Ethernet cards connected by a cable. using ip tool you can easily assign one of the pair to the container's namespace and the other somewhere else. Ideally to Linux bridge or Open vSwitch so we can create virtual networks.","title":"Virtual Ethernet devices"},{"location":"networking/#connecting-containers-using-bridge","text":"Using the Linux bridge is the easiest, we create the bridge which we call here diyc0 and assign it IPv4 address 172.16.0.1/24 . # Create the bridge $ ip link add name diyc0 type bridge # Assign it IPv4 $ ip addr add dev diyc0 172.16.0.1/24 $ ip link set diyc0 up Before we run the container we connect the created vethXYZ device to the bridge that's the host half of the pair. The other one is later added to the network namespace of the container, effectively connecting the two namespace. # Create the veth pair $ ip link add vethXYZ type veth peer name veth1 # Connect the host half to bridge $ ip link set vethXYZ master diyc0 # Add the veth1 to the container's network namespace # <PID> is pid of the container process $ ip link set veth1 netns <PID> Below: Connecting containers using veth pairs and Linux bridge Code Code in diyC uses system() function to shell out so you can easily replicate it on the command line. diyc.c:265-302","title":"Connecting containers using bridge"},{"location":"networking/#iptables","text":"Once the containers are hooked up using veth pairs and a bridge it comes to iptables to do NAT and routing to allow containers to connect to the outer world. See the net-setup code in the Makefile to inspect the exact rules. Basically setup NAT and forwarding on the container network in our case 172.16.0.0/16 .","title":"iptables"},{"location":"networking/#more-to-read","text":"Linux Switching \u2013 Interconnecting Namespaces Linux Network Namespaces","title":"More to read"},{"location":"diyc/install/","text":"Getting started # iptables diyC plays with iptables to get the routing and isolation running so if you have your own iptables rules make sure to save them before doing anything else. Just sudo iptables-save and sudo iptables-restore to recover them in case something goes awry. Prerequisites # This is a educational piece of software and has not been tested on many systems yet, to give it a go make sure you have the following: recent Linux kernel supporting needed namespaces and cgroups overlayfs ip tool ( iproute2 package ) iptables gcc make bash Overlayfs is in the mainline kernel so it everything should be straight forward it was merged in version 3.18 but has been improved a lot so you should aim for kernel 4.x and in that case you have all the namespaces and cgroups too. Kernel configuration Kernel needs to be configured to support following namespaces PID, mount, network and UTS, cgroups are needed as well. Most of the GNU/Linux distros have this support enabled by default. Installation # make setup It creates the necessary directory structure as well as prepares the networking part like iptables rules, bridge (diyc0) and so on. To remove the networking bits like bridge and iptables rules run make net-clean which removes them all. make Builds the runtime. Done Preparing images # The image import and creation is not present but because images are just TARBALLS there is no need for anything fancy. Creating the tarball using docker # Using docker is the most straightforward. docker pull the image you want, spin it up by docker run -ti <image> <command> and in different terminal do docker export <container> > myimage.tar . You have the tarball ready. Installing image # make setup creates an images subdirectory so mkdir images/myimage followed by tar -xf myimage.tar -C images/myimage/ should do the trick. The relation of images and containers is described in a section of it's own. Images and Containers . Example See how to run a container","title":"Installation"},{"location":"diyc/install/#getting-started","text":"iptables diyC plays with iptables to get the routing and isolation running so if you have your own iptables rules make sure to save them before doing anything else. Just sudo iptables-save and sudo iptables-restore to recover them in case something goes awry.","title":"Getting started"},{"location":"diyc/install/#prerequisites","text":"This is a educational piece of software and has not been tested on many systems yet, to give it a go make sure you have the following: recent Linux kernel supporting needed namespaces and cgroups overlayfs ip tool ( iproute2 package ) iptables gcc make bash Overlayfs is in the mainline kernel so it everything should be straight forward it was merged in version 3.18 but has been improved a lot so you should aim for kernel 4.x and in that case you have all the namespaces and cgroups too. Kernel configuration Kernel needs to be configured to support following namespaces PID, mount, network and UTS, cgroups are needed as well. Most of the GNU/Linux distros have this support enabled by default.","title":"Prerequisites"},{"location":"diyc/install/#installation","text":"make setup It creates the necessary directory structure as well as prepares the networking part like iptables rules, bridge (diyc0) and so on. To remove the networking bits like bridge and iptables rules run make net-clean which removes them all. make Builds the runtime. Done","title":"Installation"},{"location":"diyc/install/#preparing-images","text":"The image import and creation is not present but because images are just TARBALLS there is no need for anything fancy.","title":"Preparing images"},{"location":"diyc/install/#creating-the-tarball-using-docker","text":"Using docker is the most straightforward. docker pull the image you want, spin it up by docker run -ti <image> <command> and in different terminal do docker export <container> > myimage.tar . You have the tarball ready.","title":"Creating the tarball using docker"},{"location":"diyc/install/#installing-image","text":"make setup creates an images subdirectory so mkdir images/myimage followed by tar -xf myimage.tar -C images/myimage/ should do the trick. The relation of images and containers is described in a section of it's own. Images and Containers . Example See how to run a container","title":"Installing image"},{"location":"diyc/usage/","text":"Usage # diyc [hv][-m NUMBER] [-ip IPV4 ADDRESS] <NAME> <IMAGE> <CMD> -h, --help print the help -i, --ip ip address of the container, if not set then host network is used. It must be in the 172.16.0/16 network as the bridge diyc0 is 172.16.0.1 -m, --mem maximum size of the memory in MB allowed for the container by default there no explicit limit defined. -v, --verbose more verbose output <NAME> name of the container, needs to be unique <IMAGE> image to be used for the container, must be a directory name under the images directory <CMD> command to be executed inside the container Example: Get a container running # This is an example session showing how to get a container with minimal debian based system up and running from zero. $ git clone git@github.com:w-vi/diyc.git Cloning into 'diyc'... remote: Counting objects: 9, done. remote: Compressing objects: 100% (8/8), done. remote: Total 9 (delta 1), reused 9 (delta 1), pack-reused 0 Receiving objects: 100% (9/9), 12.95 KiB | 0 bytes/s, done. Resolving deltas: 100% (1/1), done. $ cd diyc $ make setup sudo iptables -A FORWARD -i enp5s0 -o veth -j ACCEPT || true sudo iptables -A FORWARD -o enp5s0 -i veth -j ACCEPT || true sudo iptables -t nat -A POSTROUTING -s 172.16.0.0/16 -j MASQUERADE || true sudo ip link add name diyc0 type bridge || true sudo ip addr add dev diyc0 172.16.0.1/24 || true sudo ip link set diyc0 up || true sudo iptables -A FORWARD -i enp5s0 -o diyc0 -j ACCEPT || true sudo iptables -A FORWARD -o enp5s0 -i diyc0 -j ACCEPT || true sudo iptables -A FORWARD -o diyc0 -i diyc0 -j ACCEPT || true mkdir -p containers mkdir -p images $ make gcc -std=c99 -Wall -Werror -O2 src/diyc.c -o diyc gcc -std=c99 -Wall -Werror -O2 src/nsexec.c -o nsexec $ docker pull debian Using default tag: latest latest: Pulling from library/debian Digest: sha256:72f784399fd2719b4cb4e16ef8e369a39dc67f53d978cd3e2e7bf4e502c7b793 Status: Image is up to date for debian:latest $ docker run -ti debian /bin/bash $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2c924241399c debian \"/bin/bash\" 21 seconds ago Up 20 seconds epic_leavitt $ docker export 2c924241399c >! debian.tar $ mkdir images/debian $ tar -xf debian.tar -C images/debian/ $ sudo ./diyc my1 debian bash root@my1:/> exit exit Example: Network between two containers # Spin up two different containers with different IPs. In this case it they are based on debian so Python and curl need to be installed first. $ sudo ./diyc -i 172.16.0.30 server debian bash root@server:/> apt-get update && apt-get install python root@server:/> python -m SimpleHTTPServer Serving HTTP on 0.0.0.0 port 8000 ... $ sudo ./diyc -i 172.16.0.31 client debian bash root@client:/> apt-get update && apt-get install curl root@client:/> curl http://172.16.0.30:8000 # it is accessible from the host too $ curl http://172.16.0.30:8000 Example: Limit memory used by cgroups # Having an image with python or perl installed you can easily see the OOM killer in action. We will allow only 10 MB of memory. $ sudo ./diyc -m 10 cgroup debian bash root@cgroup:/> python -c 'str = \" \" * 100000' root@cgroup:/> python -c 'str = \" \" * 1000000' root@cgroup:/> python -c 'str = \" \" * 10000000' Killed Removing exited containers # Because containers after exit leave their filesystem behind and it is not destroyed you can run it again. The data are stored in the containers/<name>/ directory so as long as this directory exists you can start and stop the container. To remove it just sudo rm -rf containers/<name> . Removing the diyc0 bridge and iptables rules # Just run make net-clean .","title":"Running containers"},{"location":"diyc/usage/#usage","text":"diyc [hv][-m NUMBER] [-ip IPV4 ADDRESS] <NAME> <IMAGE> <CMD> -h, --help print the help -i, --ip ip address of the container, if not set then host network is used. It must be in the 172.16.0/16 network as the bridge diyc0 is 172.16.0.1 -m, --mem maximum size of the memory in MB allowed for the container by default there no explicit limit defined. -v, --verbose more verbose output <NAME> name of the container, needs to be unique <IMAGE> image to be used for the container, must be a directory name under the images directory <CMD> command to be executed inside the container","title":"Usage"},{"location":"diyc/usage/#example-get-a-container-running","text":"This is an example session showing how to get a container with minimal debian based system up and running from zero. $ git clone git@github.com:w-vi/diyc.git Cloning into 'diyc'... remote: Counting objects: 9, done. remote: Compressing objects: 100% (8/8), done. remote: Total 9 (delta 1), reused 9 (delta 1), pack-reused 0 Receiving objects: 100% (9/9), 12.95 KiB | 0 bytes/s, done. Resolving deltas: 100% (1/1), done. $ cd diyc $ make setup sudo iptables -A FORWARD -i enp5s0 -o veth -j ACCEPT || true sudo iptables -A FORWARD -o enp5s0 -i veth -j ACCEPT || true sudo iptables -t nat -A POSTROUTING -s 172.16.0.0/16 -j MASQUERADE || true sudo ip link add name diyc0 type bridge || true sudo ip addr add dev diyc0 172.16.0.1/24 || true sudo ip link set diyc0 up || true sudo iptables -A FORWARD -i enp5s0 -o diyc0 -j ACCEPT || true sudo iptables -A FORWARD -o enp5s0 -i diyc0 -j ACCEPT || true sudo iptables -A FORWARD -o diyc0 -i diyc0 -j ACCEPT || true mkdir -p containers mkdir -p images $ make gcc -std=c99 -Wall -Werror -O2 src/diyc.c -o diyc gcc -std=c99 -Wall -Werror -O2 src/nsexec.c -o nsexec $ docker pull debian Using default tag: latest latest: Pulling from library/debian Digest: sha256:72f784399fd2719b4cb4e16ef8e369a39dc67f53d978cd3e2e7bf4e502c7b793 Status: Image is up to date for debian:latest $ docker run -ti debian /bin/bash $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2c924241399c debian \"/bin/bash\" 21 seconds ago Up 20 seconds epic_leavitt $ docker export 2c924241399c >! debian.tar $ mkdir images/debian $ tar -xf debian.tar -C images/debian/ $ sudo ./diyc my1 debian bash root@my1:/> exit exit","title":"Example: Get a container running"},{"location":"diyc/usage/#example-network-between-two-containers","text":"Spin up two different containers with different IPs. In this case it they are based on debian so Python and curl need to be installed first. $ sudo ./diyc -i 172.16.0.30 server debian bash root@server:/> apt-get update && apt-get install python root@server:/> python -m SimpleHTTPServer Serving HTTP on 0.0.0.0 port 8000 ... $ sudo ./diyc -i 172.16.0.31 client debian bash root@client:/> apt-get update && apt-get install curl root@client:/> curl http://172.16.0.30:8000 # it is accessible from the host too $ curl http://172.16.0.30:8000","title":"Example: Network between two containers"},{"location":"diyc/usage/#example-limit-memory-used-by-cgroups","text":"Having an image with python or perl installed you can easily see the OOM killer in action. We will allow only 10 MB of memory. $ sudo ./diyc -m 10 cgroup debian bash root@cgroup:/> python -c 'str = \" \" * 100000' root@cgroup:/> python -c 'str = \" \" * 1000000' root@cgroup:/> python -c 'str = \" \" * 10000000' Killed","title":"Example: Limit memory used by cgroups"},{"location":"diyc/usage/#removing-exited-containers","text":"Because containers after exit leave their filesystem behind and it is not destroyed you can run it again. The data are stored in the containers/<name>/ directory so as long as this directory exists you can start and stop the container. To remove it just sudo rm -rf containers/<name> .","title":"Removing exited containers"},{"location":"diyc/usage/#removing-the-diyc0-bridge-and-iptables-rules","text":"Just run make net-clean .","title":"Removing the diyc0 bridge and iptables rules"}]}